{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-11 14:15:44.317200: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.1/lib64:/usr/local/cuda-10.1/lib64:/usr/local/cuda-10.1/lib64\n",
      "2021-10-11 14:15:44.317249: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "\n",
    "from model import Model, torch_load_all\n",
    "from config import CNNConfig\n",
    "from data_utils import ESDataset, collate_fn\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeLsum'], use_stemmer=True)\n",
    "\n",
    "def torch_save(dir, save_dict):\n",
    "    os.makedirs(dir, exist_ok=True)\n",
    "\n",
    "    for name in save_dict:\n",
    "        torch.save(save_dict[name], os.path.join(dir, name + '.pt'))\n",
    "    \n",
    "def torch_load_all(dir):\n",
    "    save_dict = {}\n",
    "    for name in os.listdir(dir):\n",
    "        save_dict[name.replace('.pt', '')] = torch.load(os.path.join(dir, name), map_location=torch.device('cpu'))\n",
    "\n",
    "    return save_dict\n",
    "\n",
    "\n",
    "def get_test_loader(tokenizer, docs, config):\n",
    "    encodings = []\n",
    "    for doc in docs:\n",
    "        encodings.append(tokenizer(doc[:config.MAX_DOC_LEN], truncation=True,\n",
    "                                   max_length=config.MAX_SEQ_LEN, padding='max_length'))\n",
    "    \n",
    "    test_dataset = ESDataset(encodings)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "    return test_loader\n",
    "\n",
    "def get_all_probs(model, tokenizer, all_doc, config):\n",
    "    res = []\n",
    "    test_loader = get_test_loader(tokenizer, all_doc, config=config)\n",
    "    for item in tqdm(test_loader):\n",
    "        ids = item['input_ids'].to(config.device)\n",
    "        document_mask = item['document_mask'].to(config.device)\n",
    "        attention_mask = item['attention_mask'].to(config.device)\n",
    "        prob = model(ids, document_mask, attention_mask)[0].tolist()\n",
    "        res.append(prob)\n",
    "            \n",
    "    return res\n",
    "\n",
    "def calculateSimilarity(sentence, doc):\n",
    "    score = scorer.score('\\n'.join(doc), sentence)\n",
    "    return np.mean([score['rouge2'][2], score['rougeLsum'][2]])\n",
    "\n",
    "def choose_summary_mmr(doc, prob, k=3, alpha=0.9):\n",
    "    prob = np.array(prob)\n",
    "    idx = [np.argmax(prob)]\n",
    "    prob[idx[0]] = 0\n",
    "    summary = [doc[idx[0]]]\n",
    "\n",
    "    while len(idx) < min(k, len(doc)):\n",
    "        mmr = -100 * np.ones_like(prob)\n",
    "        for i, sent in enumerate(doc):\n",
    "            if prob[i] != 0:\n",
    "                mmr[i] = alpha * prob[i] - (1-alpha) * calculateSimilarity(sent, summary)\n",
    "        pos = np.argmax(mmr)\n",
    "        prob[pos] = 0\n",
    "        summary.append(doc[pos])\n",
    "        idx.append(pos)\n",
    "    summary = sorted(list(zip(idx, summary)), key=lambda x: x[0])\n",
    "    return [x[1] for x in summary]\n",
    "\n",
    "def choose_summary(doc, prob, k=3):\n",
    "    idx = torch.topk(torch.tensor(prob), k=k).indices.tolist()\n",
    "    return [doc[i] for i in sorted(idx)]\n",
    "\n",
    "def choose_all_summary(docs, all_probs, k=3):\n",
    "    summaries = []\n",
    "    for i, doc in enumerate(docs):\n",
    "        prob = all_probs[i]\n",
    "        idx = torch.topk(torch.tensor(prob), k=k).indices.tolist()\n",
    "        summaries.append([doc[i] for i in sorted(idx)])\n",
    "    return summaries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize as nltk_sent_tokenize\n",
    "\n",
    "def sent_tokenize(doc):\n",
    "    return nltk_sent_tokenize(doc)\n",
    "\n",
    "# load the trained model\n",
    "final_dict = torch_load_all('save/cnn/best-model')\n",
    "config = final_dict['config']\n",
    "config.device = 'cpu'\n",
    "\n",
    "bert = config.bert_type.from_pretrained(config.bert_name)\n",
    "tokenizer = config.tokenizer_type.from_pretrained(config.bert_name)\n",
    "model = Model(bert, config).to(config.device)\n",
    "model.load_state_dict(final_dict['model_state_dict'])\n",
    "model.eval()\n",
    "a = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/cnndm/example.txt') as f:\n",
    "    doc = f.read()\n",
    "doc = sent_tokenize(doc)\n",
    "# doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]/mnt/disk1/tan_hm/venv/lib/python3.7/site-packages/torch/nn/functional.py:1625: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.06it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['(CNN) — After a long, golden sunset of being installed on fewer and fewer aircraft, the retirement of older aircraft caused by the Covid-19 pandemic means that when air travel resumes, international first class will be very nearly a thing of the past.',\n",
       "  'Its replacement is a new generation of superbusiness minisuites, more spacious than regular business class, and with a privacy door to create your own space, but without the over-the-top luxury of first class.',\n",
       "  'The Qsuite is unique to Qatar Airways, but a growing number of airlines offer or plan to offer superbusiness seats, from Delta to China Eastern, JetBlue to British Airways, Shanghai Airlines to Aeroflot, to the very latest, Air China.']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = [doc]\n",
    "probs = get_all_probs(model, tokenizer, docs, config)\n",
    "sumamries = choose_all_summary(docs, probs, k=3)\n",
    "sumamries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vietnamese version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Zayt/viRoberta-l6-h384-word-cased were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at Zayt/viRoberta-l6-h384-word-cased and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from underthesea import sent_tokenize as  sent_tokenize_uts, word_tokenize as word_tokenize_uts\n",
    "\n",
    "def sent_tokenize(doc):\n",
    "    return sent_tokenize_uts(doc)\n",
    "\n",
    "def word_tokenize(doc, format='text'):\n",
    "    return  word_tokenize_uts(doc, format=format)\n",
    "\n",
    "# load the trained model\n",
    "final_dict = torch_load_all('save/vietnews/best-model-f1')\n",
    "config = final_dict['config']\n",
    "config.device = 'cpu'\n",
    "\n",
    "bert = config.bert_type.from_pretrained(config.bert_name)\n",
    "tokenizer = config.tokenizer_type.from_pretrained(config.bert_name)\n",
    "model = Model(bert, config).to(config.device)\n",
    "model.load_state_dict(final_dict['model_state_dict'])\n",
    "model.eval()\n",
    "a = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Theo trang The_Guardian ( Anh ) , tuyên_bố này được đưa ra vào cuối cuộc hội_đàm trực_tiếp đầu_tiên giữa Mỹ và Taliban kể từ khi Washington rút quân khỏi Afghanistan hồi cuối tháng 8 vừa_qua , chấm_dứt sự hiện_diện quân_sự kéo_dài 20 năm tại quốc_gia Trung Nam_Á .',\n",
       " 'Phát_ngôn_viên chính_trị của Taliban_Suhail_Shaheen cho biết cuộc đàm_phán giữa họ và Mỹ ở Doha ( Qatar ) đã đạt được kết_quả tốt_đẹp .',\n",
       " 'Washington đồng_ý viện_trợ nhân_đạo cho Afghanistan nhưng nhấn_mạnh viện_trợ đó không đồng_nghĩa với việc chính_thức công_nhận chính_quyền Taliban ở Afghanistan .',\n",
       " 'Trong khi đó , phía Mỹ chỉ tiết_lộ hai bên \" đã thảo_luận về việc cung_cấp viện_trợ nhân_đạo trực_tiếp cho người dân Afghanistan \" .',\n",
       " 'Người_phát_ngôn Bộ Ngoại_giao Ned_Price gọi các cuộc thảo_luận là \" thẳng_thắn và chuyên_nghiệp \" , trong đó Mỹ nhắc lại rằng sẽ đánh_giá Taliban dựa trên hành_động của họ thay_vì lời_nói . \"',\n",
       " 'Phái_đoàn Mỹ tập_trung vào các mối quan_tâm về an_ninh , khủng_bố và sơ_tán an_toàn cho công_dân Mỹ , các công_dân nước_ngoài khác và các đối_tác Afghanistan của chúng_tôi , cũng như vấn_đề nhân_quyền , bao_gồm vai_trò của phụ_nữ và trẻ_em_gái trong mọi khía_cạnh của xã_hội Afghanistan \" , ông Price nói trong một tuyên_bố .',\n",
       " 'Trước đó , hôm 8/10 , người phát_ngôn của Bộ Ngoại_giao Mỹ cũng cho biết cuộc gặp này không phải là để công_nhận hoặc hợp_pháp_hóa chính_quyền Taliban tại Afghanistan , mà là để tiếp_tục các cuộc đàm_phán về những vấn_đề liên_quan lợi_ích quốc_gia của Mỹ .',\n",
       " 'Tuy_nhiên , hôm 10/10 , Taliban đã từ_chối hợp_tác với Washington trong việc đối_phó với lực_lượng chân_rết của Tổ_chức Nhà_nước Hồi_giáo ( IS ) đang hoạt_động mạnh_mẽ ở Afghanistan .',\n",
       " 'Các nhóm khủng_bố , đặc_biệt là IS , đã trở_thành vấn_đề đau_đầu với Taliban kể từ khi lực_lượng này lên nắm quyền ._IS-K , nhánh Afghanistan của IS , đang ngày_càng manh_động với nhiều vụ tấn_công nhắm vào dân_thường lẫn Taliban .',\n",
       " 'Tổ_chức này đứng sau vụ đánh bom khiến hàng chục người Afghanistan và 13 quân_nhân Mỹ thiệt_mạng hồi cuối tháng 8 .',\n",
       " 'Mới_đây nhất , nhóm này nhận trách_nhiệm_vụ đánh bom nhằm vào giáo_đường Hồi_giáo ở Kunduz làm trên 70 người chết và nhiều người bị_thương hôm 9/10 .',\n",
       " 'Sau khi giành quyền kiểm_soát Afghanistan hôm 15/8 , chính_quyền Taliban phải đối_mặt với nhiều thách_thức , trong đó có cuộc khủng_hoảng_kinh_tế , nhân_đạo .',\n",
       " 'Ngoài_ra , Taliban cũng đang nỗ_lực thuyết_phục cộng_đồng quốc_tế công_nhận chính_quyền mới của mình ở Afghanistan .']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('data/vietnews/example.txt') as f:\n",
    "    title, summary, doc = f.read().split('\\n\\n')\n",
    "doc = sent_tokenize(word_tokenize(doc))\n",
    "# doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]/mnt/disk1/tan_hm/venv/lib/python3.7/site-packages/torch/nn/functional.py:1625: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.73it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['Theo trang The_Guardian ( Anh ) , tuyên_bố này được đưa ra vào cuối cuộc hội_đàm trực_tiếp đầu_tiên giữa Mỹ và Taliban kể từ khi Washington rút quân khỏi Afghanistan hồi cuối tháng 8 vừa_qua , chấm_dứt sự hiện_diện quân_sự kéo_dài 20 năm tại quốc_gia Trung Nam_Á .',\n",
       "  'Washington đồng_ý viện_trợ nhân_đạo cho Afghanistan nhưng nhấn_mạnh viện_trợ đó không đồng_nghĩa với việc chính_thức công_nhận chính_quyền Taliban ở Afghanistan .']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = [doc]\n",
    "probs = get_all_probs(model, tokenizer, docs, config)\n",
    "sumamries = choose_all_summary(docs, probs, k=2)\n",
    "sumamries"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "62257e83c93fa3387442bd5aebc80bdf7ed58eaa472b333d9af121b22db2a637"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
