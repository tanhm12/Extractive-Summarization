{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from rouge_score import rouge_scorer\n",
    "from nltk.tokenize import sent_tokenize as nltk_sent_tokenize\n",
    "\n",
    "from model import Model, torch_load_all\n",
    "from config import CNNConfig\n",
    "from data_utils import ESDataset, collate_fn\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeLsum'], use_stemmer=True)\n",
    "\n",
    "def sent_tokenize(doc):\n",
    "    return nltk_sent_tokenize(doc)\n",
    "\n",
    "def get_test_loader(tokenizer, docs, config):\n",
    "    encodings = []\n",
    "    for doc in docs:\n",
    "        encodings.append(tokenizer(doc[:config.MAX_DOC_LEN], truncation=True,\n",
    "                                   max_length=config.MAX_SEQ_LEN, padding='max_length'))\n",
    "    \n",
    "    test_dataset = ESDataset(encodings)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "    return test_loader\n",
    "\n",
    "def get_all_probs(model, tokenizer, all_doc, config):\n",
    "    res = []\n",
    "    test_loader = get_test_loader(tokenizer, all_doc, config=config)\n",
    "    for item in tqdm(test_loader):\n",
    "        ids = item['input_ids'].to(config.device)\n",
    "        document_mask = item['document_mask'].to(config.device)\n",
    "        attention_mask = item['attention_mask'].to(config.device)\n",
    "        prob = model(ids, document_mask, attention_mask)[0].tolist()\n",
    "        res.append(prob)\n",
    "            \n",
    "    return res\n",
    "\n",
    "def calculateSimilarity(sentence, doc):\n",
    "    score = scorer.score('\\n'.join(doc), sentence)\n",
    "    return np.mean([score['rouge2'][2], score['rougeLsum'][2]])\n",
    "\n",
    "def choose_summary_mmr(doc, prob, k=3, alpha=0.9):\n",
    "    prob = np.array(prob)\n",
    "    idx = [np.argmax(prob)]\n",
    "    prob[idx[0]] = 0\n",
    "    summary = [doc[idx[0]]]\n",
    "\n",
    "    while len(idx) < min(k, len(doc)):\n",
    "        mmr = -100 * np.ones_like(prob)\n",
    "        for i, sent in enumerate(doc):\n",
    "            if prob[i] != 0:\n",
    "                mmr[i] = alpha * prob[i] - (1-alpha) * calculateSimilarity(sent, summary)\n",
    "        pos = np.argmax(mmr)\n",
    "        prob[pos] = 0\n",
    "        summary.append(doc[pos])\n",
    "        idx.append(pos)\n",
    "    summary = sorted(list(zip(idx, summary)), key=lambda x: x[0])\n",
    "    return [x[1] for x in summary]\n",
    "\n",
    "def choose_summary(doc, prob, k=3):\n",
    "    idx = torch.topk(torch.tensor(prob), k=k).indices.tolist()\n",
    "    return [doc[i] for i in sorted(idx)]\n",
    "\n",
    "def choose_all_summary(docs, all_probs, k=3):\n",
    "    summaries = []\n",
    "    for i, doc in enumerate(docs):\n",
    "        prob = all_probs[i]\n",
    "        idx = torch.topk(torch.tensor(prob), k=k).indices.tolist()\n",
    "        summaries.append([doc[i] for i in sorted(idx)])\n",
    "    return summaries\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-10-07 00:08:37.980039: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.1/lib64:/usr/local/cuda-10.1/lib64:\n",
      "2021-10-07 00:08:37.980075: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# load the trained model\n",
    "final_dict = torch_load_all('save/cnn/best-model')\n",
    "config = CNNConfig()\n",
    "config.device = 'cpu'\n",
    "\n",
    "bert = config.bert_type.from_pretrained(config.bert_name)\n",
    "tokenizer = config.tokenizer_type.from_pretrained(config.bert_name)\n",
    "model = Model(bert, config).to(config.device)\n",
    "model.load_state_dict(final_dict['model_state_dict'])\n",
    "# model.eval()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-small were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "with open('data/cnndm/example.txt') as f:\n",
    "    doc = f.read()\n",
    "doc = sent_tokenize(doc)\n",
    "# doc"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "docs = [doc]\n",
    "probs = get_all_probs(model, tokenizer, docs, config)\n",
    "sumamries = choose_all_summary(docs, probs, k=3)\n",
    "sumamries"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]/mnt/disk1/tan_hm/venv/lib/python3.7/site-packages/torch/nn/functional.py:1625: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.48it/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[['(CNN) — After a long, golden sunset of being installed on fewer and fewer aircraft, the retirement of older aircraft caused by the Covid-19 pandemic means that when air travel resumes, international first class will be very nearly a thing of the past.',\n",
       "  'Its replacement is a new generation of superbusiness minisuites, more spacious than regular business class, and with a privacy door to create your own space, but without the over-the-top luxury of first class.',\n",
       "  'The Qsuite is unique to Qatar Airways, but a growing number of airlines offer or plan to offer superbusiness seats, from Delta to China Eastern, JetBlue to British Airways, Shanghai Airlines to Aeroflot, to the very latest, Air China.']]"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit ('venv': venv)"
  },
  "interpreter": {
   "hash": "001563a95dc8b565e74778be5986e3895a5b5171a6836a45578c2beb3674daaa"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}