{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Header"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# !pip install transformers\n",
    "# !pip install sentencepiece\n",
    "# !pip install rouge-score\n",
    "# !wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=0BwmD_VLjROrfTHk4NFg2SndKcjQ' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=0BwmD_VLjROrfTHk4NFg2SndKcjQ\" -O cnn_stories.tgz && rm -rf /tmp/cookies.txt\n",
    "# !tar -xzf \"cnn_stories.tgz\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import json\n",
    "import os\n",
    "import stanza\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import torch \n",
    "\n",
    "from rouge_score import rouge_scorer\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from transformers import BertModel, BertTokenizerFast\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from torch.nn import LSTM, Conv2d, Linear\n",
    "from torch.nn.functional import max_pool2d\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-09-27 14:43:51.781056: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.1/lib64:/usr/local/cuda-10.1/lib64:/usr/local/cuda-10.1/lib64\n",
      "2021-09-27 14:43:51.781094: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data pre-processing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# url list from https://github.com/abisee/cnn-dailymail\n",
    "with open('data/cnndm/filenames/cnn_files.json') as f:\n",
    "    filenames = json.load(f)\n",
    "\n",
    "train_files = filenames['train']\n",
    "valid_files = filenames['valid']\n",
    "test_files = filenames['test']\n",
    "\n",
    "\n",
    "# stanza.download(lang='en')\n",
    "nlp = stanza.Pipeline(lang='en', processors='tokenize')"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0f3356c7d8b34320a31a45c640bdb1eb"
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading https://raw.githubusercontent.com/stanfordnlp…"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-09-16 13:46:52 INFO: Downloading default packages for language: en (English)...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aed9aa12bd1544eaafb619a1838a0539"
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading http://nlp.stanford.edu/software/stanza/1.2.2…"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-09-16 13:48:23 INFO: Finished downloading models and saved to /home/aimenext/stanza_resources.\n",
      "2021-09-16 13:48:23 INFO: Loading these models for language: en (English):\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | combined |\n",
      "========================\n",
      "\n",
      "2021-09-16 13:48:23 INFO: Use device: gpu\n",
      "2021-09-16 13:48:23 INFO: Loading: tokenize\n",
      "2021-09-16 13:48:34 INFO: Done loading processors!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "LOWER = False\n",
    "LENGTH_THRESHOLD = 10\n",
    "rouge_factors = {'rouge1': 0.4, 'rouge2': 0.3, 'rougeL': 0.3}  \n",
    "\n",
    "def sent_tokenize(doc):\n",
    "    doc = nlp(doc)\n",
    "    sentences = []\n",
    "    for sentence in doc.sentences:\n",
    "        # print(sentence.tokens[0])\n",
    "        sentence = ' '.join([token.text for token in sentence.tokens])\n",
    "        if len(sentence) > LENGTH_THRESHOLD:\n",
    "            sentences.append(sentence)\n",
    "    \n",
    "    return sentences\n",
    "\n",
    "def reconstruct_text(text):\n",
    "    return re.sub('\\s([?.!\"](?:\\s|$))', '', text)\n",
    "\n",
    "def parse_file(file):\n",
    "    with open(file, encoding='utf-8') as f:\n",
    "        document = f.read().rstrip().split(\"\\n\\n@highlight\\n\\n\")\n",
    "    summary = document[1:]\n",
    "    doc = sent_tokenize(document[0])\n",
    "    return doc, summary\n",
    "\n",
    "\n",
    "def make_label(doc, sum, scorer):\n",
    "    doc_size = len(doc)\n",
    "    res = [0] * doc_size\n",
    "    n = min(len(sum), doc_size)\n",
    "    # f1 of rouge-L\n",
    "    for j in range(n):\n",
    "        # score = [scorer.score(sum[j], sent_i)['rouge2'][2] for sent_i in doc]\n",
    "        score = [scorer.score(sum[j], sent_i) for sent_i in doc]\n",
    "        score = [( \n",
    "            # x['rouge1'][2] * rouge_factors['rouge1'] + \\\n",
    "            x['rouge2'][2] * rouge_factors['rouge2'] + \\\n",
    "            x['rougeL'][2] * rouge_factors['rougeL']\n",
    "            ) for x in score]\n",
    "        sent_pos = np.argmax(score)\n",
    "        for i in range(doc_size):\n",
    "            if res[sent_pos] == 1:\n",
    "                score[sent_pos] = 0\n",
    "                sent_pos = np.argmax(score)\n",
    "            else:\n",
    "                res[sent_pos] = 1\n",
    "                break\n",
    "        # print(score[sent_pos])\n",
    "        # print(doc[sent_pos])\n",
    "        # print(sum[j], \"\\n\")\n",
    "    return res\n",
    "\n",
    "def process(data_dir, files):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    docs = {}\n",
    "    summaries = {}\n",
    "    labels = {}\n",
    "    remove_files = []\n",
    "    for idx in tqdm(range(len(files))):\n",
    "        # if idx%1000 == 0:\n",
    "        #     print('\\n', os.getpid(), idx)\n",
    "        doc, summary = parse_file(os.path.join(data_dir, files[idx]))\n",
    "        if len(doc) < len(summary) or len(doc) == 0 or len(summary) == 0:\n",
    "            remove_files.append(files[idx])   \n",
    "            continue    \n",
    "        label = make_label(doc, summary, scorer)\n",
    "        docs[files[idx]] = doc\n",
    "        labels[files[idx]] = label\n",
    "        summaries[files[idx]] = summary\n",
    "        # if idx%5000 == 0:\n",
    "        #     a = list(zip(label, doc))\n",
    "        #     for i in a:\n",
    "        #         print(len(i[1]), i[0], i[1])\n",
    "        #     print('##########\\n','\\n'.join(summary))\n",
    "    return docs, labels, summaries, remove_files\n",
    "\n",
    "def json_dump(obj, file):\n",
    "    with open(file, 'w', encoding='utf8') as f:\n",
    "        json.dump(obj, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "def process_and_write(data_dir, files, write_dir):\n",
    "    docs, labels, summaries, remove_files = process(data_dir, files)\n",
    "\n",
    "    os.makedirs(write_dir, exist_ok=True)\n",
    "    json_dump(docs, os.path.join(write_dir, 'docs.json'))\n",
    "    json_dump(labels, os.path.join(write_dir, 'labels.json'))\n",
    "    json_dump(summaries, os.path.join(write_dir, 'summaries.json'))\n",
    "    json_dump(remove_files, os.path.join(write_dir, 'remove_files.json'))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "base_write_dir = 'data/cnndm/cnn'\n",
    "process_and_write('cnn/stories', valid_files, os.path.join(base_write_dir, 'valid'))\n",
    "process_and_write('cnn/stories', train_files, os.path.join(base_write_dir, 'train'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data processing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.train_data_dir = 'data/cnndm/cnn/train'\n",
    "        self.val_data_dir = 'data/cnndm/cnn/valid'\n",
    "\n",
    "        self.MAX_SEQ_LEN = 128\n",
    "        self.MAX_DOC_LEN = 48\n",
    "\n",
    "        self.bert_hidden = 512\n",
    "        self.bert_n_layers = 4\n",
    "\n",
    "        self.windows_size = [1, 3, 5, 10]\n",
    "        self.out_channels = 50\n",
    "        self.lstm_hidden = 512\n",
    "        self.device = 'cpu'\n",
    "\n",
    "        self.batch_size = 4\n",
    "        self.num_epochs = 10\n",
    "        self.print_freq = 0.05\n",
    "        self.save_dir = './save'\n",
    "\n",
    "config = Config()\n",
    "# config.__dict__"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'train_data_dir': 'data/cnndm/cnn/train',\n",
       " 'val_data_dir': 'data/cnndm/cnn/valid',\n",
       " 'MAX_SEQ_LEN': 128,\n",
       " 'MAX_DOC_LEN': 48,\n",
       " 'bert_hidden': 512,\n",
       " 'bert_n_layers': 4,\n",
       " 'windows_size': [1, 3, 5, 10],\n",
       " 'out_channels': 50,\n",
       " 'lstm_hidden': 512,\n",
       " 'device': 'cpu'}"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained('prajjwal1/bert-small')\n",
    "\n",
    "def load_json(file):\n",
    "    with open(file) as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def load_text(dir):\n",
    "    docs = load_json(os.path.join(dir, 'docs.json'))\n",
    "    labels = load_json(os.path.join(dir, 'labels.json'))\n",
    "    return docs, labels\n",
    "\n",
    "def get_encodings(docs, labels):\n",
    "    keys = list(docs.keys())\n",
    "    encodings = []\n",
    "    return_labels = []\n",
    "\n",
    "    for k in tqdm(keys):\n",
    "        encodings.append(tokenizer(docs[k][:config.MAX_DOC_LEN], truncation=True,\n",
    "                                   max_length=config.MAX_SEQ_LEN, padding='max_length'))\n",
    "        return_labels.append(labels[k][:config.MAX_DOC_LEN])\n",
    "    \n",
    "    return keys, encodings, return_labels\n",
    "\n",
    "# train_texts, train_labels = load_text(config.train_data_dir)\n",
    "val_texts, val_dict_labels = load_text(config.val_data_dir)\n",
    "\n",
    "# train_encodings = tokenizer(, truncation=True, max_length=config.MAX_SEQ_LEN, padding='max_length')\n",
    "val_keys, val_encodings, val_labels = get_encodings(val_texts, val_dict_labels)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 1220/1220 [00:05<00:00, 217.64it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "class ESDataset(Dataset):\n",
    "    def __init__(self, encodings, labels=None, keys=None, config=config):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "        self.keys = keys\n",
    "        self.encoding_keys = ['input_ids', 'attention_mask']\n",
    "\n",
    "        self.config = config\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(self.encodings[idx][key]) for key in self.encoding_keys}\n",
    "        if self.labels is not None:\n",
    "            item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings)\n",
    "\n",
    "def collate_fn(data, device=config.device):\n",
    "    keys = data[0].keys()\n",
    "\n",
    "    result = {k: [item[k] for item in data] for k in keys}\n",
    "    input_ids = result['input_ids']\n",
    "    result['document_mask'] = [torch.tensor([1] * len(input_ids[i])) for i in range(len(input_ids))]\n",
    "    \n",
    "\n",
    "    for k in result:\n",
    "        result[k] = pad_sequence(result[k], batch_first=True).to(device)\n",
    "    \n",
    "    return result\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "dataset = ESDataset(val_encodings, val_labels, val_keys)\n",
    "data_loader = DataLoader(dataset, batch_size=3, shuffle=True, collate_fn=collate_fn)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "bert = BertModel.from_pretrained('prajjwal1/bert-small')"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3e98be5aafb942aa806500c187d92c14"
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=286.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "83774af185da44fe8ac28b22fcc8b7fe"
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=116270890.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "class Bert_Embedding(nn.Module):\n",
    "    def __init__(self, bert, config=config):\n",
    "        super(Bert_Embedding, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.bert_hidden = config.bert_hidden * config.bert_n_layers\n",
    "        self.get_n_layers = config.bert_n_layers\n",
    "        self.config = config\n",
    "        \n",
    "        self.windows_size = config.windows_size\n",
    "        self.out_channels = config.out_channels\n",
    "        self.lstm_embedding_size = len(self.windows_size) * config.MAX_SEQ_LEN  \n",
    "        self.filters = nn.ModuleList([nn.Conv2d(1, self.out_channels,\n",
    "                                                (i, self.bert_hidden)) for i in self.windows_size])\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x, document_mask, attention_mask):\n",
    "        lens = [mask_i.sum().item() for mask_i in document_mask]\n",
    "\n",
    "        batch, doc_len, seq_len = list(x.shape)\n",
    "        x = x.reshape((batch*doc_len, seq_len))\n",
    "        attention_mask = attention_mask.reshape((batch*doc_len, seq_len))        \n",
    "\n",
    "        last_hds, pooler_output, hidden_states = self.bert(x, attention_mask, output_hidden_states=True)\n",
    "        embeddings = torch.cat(hidden_states[-self.get_n_layers:], axis=-1)  # batch, doc_len, seq_len, self.bert_hidden\n",
    "        print(embeddings.shape)\n",
    "        embeddings = embeddings.reshape((batch * doc_len, 1,  seq_len, self.bert_hidden))  # batch * doc_len, 1, MAX_SEQ_LEN, bert_hidden\n",
    "        lstm_inputs = []\n",
    "\n",
    "        for i in range(len(self.windows_size)):\n",
    "            temp_out = self.filters[i](embeddings).squeeze(-1)  # batch * doc_len, self.out_channels, MAX_SEQ_LEN - self.windows_size[i] + 1\n",
    "            cnn_result = torch.mean(temp_out, dim=1) # average along out_channels axis\n",
    "            if cnn_result.shape[1] < self.config.MAX_SEQ_LEN: # pad cnn_result to MAX_SEQ_LEN\n",
    "                pad_tensor = torch.zeros((cnn_result.shape[0], self.config.MAX_SEQ_LEN - cnn_result.shape[1])).to(cnn_result.device)\n",
    "                cnn_result = torch.cat([cnn_result, pad_tensor], axis=1)\n",
    "            lstm_inputs.append(cnn_result)\n",
    "        lstm_inputs = torch.cat(lstm_inputs, dim=-1).reshape((batch, doc_len, self.lstm_embedding_size))  \n",
    "        lstm_inputs = pack_padded_sequence(lstm_inputs, lens, batch_first=True, enforce_sorted=False)\n",
    "\n",
    "        return lstm_inputs\n",
    "\n",
    "\n",
    "class Document_Encoder(nn.Module):\n",
    "    def __init__(self, embedding_size=350, config=config):\n",
    "        super(Document_Encoder, self).__init__()\n",
    "\n",
    "        self.config = config\n",
    "        self.embedding_size = embedding_size\n",
    "        self.doc_encoder = nn.LSTM(self.embedding_size, config.lstm_hidden, num_layers=1,\n",
    "                            bidirectional=True, batch_first=True)\n",
    "\n",
    "    def forward(self, lstm_inputs):\n",
    "        _, doc_encoder_out = self.doc_encoder(lstm_inputs)\n",
    "\n",
    "        return doc_encoder_out\n",
    "\n",
    "class Sentence_Extractor(nn.Module):\n",
    "    def __init__(self, embedding_size=350, config=config):\n",
    "        super(Sentence_Extractor, self).__init__()\n",
    "\n",
    "        self.config = config\n",
    "        self.embedding_size = embedding_size\n",
    "        self.sentence_extractor = nn.LSTM(self.embedding_size, config.lstm_hidden, num_layers=1,\n",
    "                                  bidirectional=True, batch_first=True)\n",
    "        self.dropout_layer = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, lstm_inputs, encoder_in):\n",
    "        out_packed, (_, __) = self.sentence_extractor(lstm_inputs, encoder_in)\n",
    "        out, out_lens = pad_packed_sequence(out_packed, batch_first=True)\n",
    "        out = self.dropout_layer(out)\n",
    "        return out\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, bert, config=config):\n",
    "        super(Model, self).__init__()\n",
    "        self.config = config\n",
    "        self.embeddings = Bert_Embedding(bert, config=config)\n",
    "        self.doc_encoder = Document_Encoder(self.embeddings.lstm_embedding_size, config=config)\n",
    "        self.sentence_extractor = Sentence_Extractor(self.embeddings.lstm_embedding_size, config=config)\n",
    "\n",
    "        self.linear = Linear(config.lstm_hidden * 2, 1) \n",
    "        self.loss_func = nn.BCELoss()\n",
    "        self.loss_padding_value = -100\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, document_mask, attention_mask, y=None):\n",
    "        lstm_inputs = self.embeddings(x, document_mask, attention_mask)\n",
    "\n",
    "        doc_encoder_out = self.doc_encoder(lstm_inputs)  \n",
    "        encoder_in = doc_encoder_out\n",
    "\n",
    "        out = self.sentence_extractor(lstm_inputs, encoder_in)\n",
    "        out = self.sigmoid(self.linear(out).squeeze(-1))\n",
    "        # print(out.shape, mask.shape)\n",
    "        # out *= mask\n",
    "        \n",
    "        if y is not None:\n",
    "            y = pad_sequence(y, batch_first=True, padding_value=self.loss_padding_value).to(out.device)\n",
    "            loss = self.loss_func(out, y)\n",
    "            return out, loss\n",
    "\n",
    "        return out"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "## Test model\n",
    "# model = Model(bert).to(config.device)\n",
    "\n",
    "# for item in data_loader:\n",
    "#     ids = item['input_ids']\n",
    "#     document_mask = item['document_mask']\n",
    "#     attention_mask = item['attention_mask']\n",
    "#     print(model(ids, document_mask, attention_mask).shape, item['labels'].shape)\n",
    "#     break\n",
    "\n",
    "config.__dict__"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def torch_save(dir, model, config, epoch=0,  optimizer=None, scheduler=None, all_train_loss=[],\n",
    "               all_dev_loss=[], best_dev_loss=1e9):\n",
    "    torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'config': config,\n",
    "            'epoch': epoch,\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'all_train_loss': all_train_loss,\n",
    "            'all_dev_loss': all_dev_loss,\n",
    "            'best_dev_loss': best_dev_loss\n",
    "            }, dir)\n",
    "    \n",
    "def torch_load(dir, model, config, optimizer=None, scheduler=None, return_config=True):\n",
    "    checkpoint = torch.load(dir)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    old_config = checkpoint['config']\n",
    "    model.to(config.device)\n",
    "\n",
    "    if optimizer is not None:\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    if scheduler is not None:\n",
    "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    all_train_loss = checkpoint['all_train_loss']\n",
    "    all_dev_loss = checkpoint['all_dev_loss']\n",
    "    best_dev_loss = checkpoint['best_dev_loss']\n",
    "    \n",
    "    if return_config:\n",
    "        return old_config, all_train_loss, all_dev_loss, best_dev_loss\n",
    "    else:\n",
    "        return all_train_loss, all_dev_loss, best_dev_loss\n",
    "\n",
    "\n",
    "\n",
    "def train(train_loader, val_loader, start_epoch=0, epochs=epochs, batch_size=batch_size, print_freq=0.5, save_dir=SAVE_DIR):\n",
    "    best_dev_loss = 1e9\n",
    "    model.train()\n",
    "    all_train_loss, all_dev_loss, best_dev_loss = torch_load(os.path.join(SAVE_DIR, 'model_{}.pt'.format(max(start_epoch-1, 0))))\n",
    "\n",
    "    start_time = time.time()\n",
    "    print_after = int(print_freq * len(x) / batch_size)\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        print_counter = 0\n",
    "        total_loss = []\n",
    "        print('epoch:', epoch)\n",
    "        for i in tqdm(range(0, len(x), batch_size)):\n",
    "            prob, loss = model.forward(x[i: i+batch_size],\n",
    "                                       mask[i: i+batch_size],\n",
    "                                       y[i: i+batch_size],\n",
    "                                       )\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "            optimizer.step()\n",
    "            total_loss.append(loss.item())\n",
    "            if i > print_counter:\n",
    "                print('step: {}, loss: {}, total loss: {}'.format(i, loss.item(), np.mean(total_loss)))\n",
    "                print_counter += print_after\n",
    "        scheduler.step()\n",
    "        \n",
    "        print('train loss:', np.mean(total_loss))\n",
    "        dev_loss = eval()\n",
    "        print('dev_loss:', dev_loss)\n",
    "        if dev_loss < best_dev_loss:\n",
    "            torch_save(os.path.join(save_dir, 'best-model.pt'),\n",
    "                   model, optimizer, scheduler, all_train_loss, all_dev_loss, best_dev_loss)\n",
    "            best_dev_loss = dev_loss\n",
    "        all_train_loss.append(total_loss)\n",
    "        all_dev_loss.append(dev_loss)\n",
    "\n",
    "        torch_save(os.path.join(save_dir, 'model_{}.pt'.format(str(epoch))),\n",
    "                   model, optimizer, scheduler, all_train_loss, all_dev_loss, best_dev_loss)\n",
    "        end_time = time.time()\n",
    "        print('Finish epoch {} at {}, in {} seconds. \\n'.format(epoch, end_time, end_time - start_time))\n",
    " \n",
    "\n",
    "def eval(x=x_valid, y=y_valid, mask=mask_valid, batch_size=batch_size, get_report=True):\n",
    "    model.eval()\n",
    "    total_loss = []\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    for i in y:\n",
    "        y_true.extend(i.tolist())\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(x), batch_size):\n",
    "            prob, loss = model.forward(x[i: i+batch_size],\n",
    "                                      mask[i: i+batch_size],\n",
    "                                      y[i: i+batch_size],\n",
    "                                      )\n",
    "            \n",
    "            temp_y_pred = [0 for _ in range(len(y[i: i+batch_size]))]\n",
    "            for j, sent in enumerate(y[i: i+batch_size]):\n",
    "                temp_prob = np.argsort(prob[j][:len(sent)].tolist())\n",
    "                temp_y_pred[j] = [0] * len(sent)\n",
    "                # print(temp_prob)\n",
    "                for k in temp_prob[-4:]:\n",
    "                    temp_y_pred[j][k] = 1\n",
    "            for sent in temp_y_pred:\n",
    "                y_pred.extend(sent)\n",
    "            total_loss.append(loss.item())\n",
    "\n",
    "    if get_report:\n",
    "        print(classification_report(y_true, y_pred))\n",
    "        \n",
    "    model.train()    \n",
    "    \n",
    "    return np.mean(total_loss)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2059861487.py, line 30)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_10879/2059861487.py\"\u001b[0;36m, line \u001b[0;32m30\u001b[0m\n\u001b[0;31m    else;\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit ('venv': venv)"
  },
  "interpreter": {
   "hash": "001563a95dc8b565e74778be5986e3895a5b5171a6836a45578c2beb3674daaa"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}