# Extractive Summarization with BERT-tiny
 - BERT-small + CNN Encoder + biLSTM Encoder-Decoder with R1/R2/RougeL : 30.94/12.50/27.58 on cnn (of cnn/dailymail) dataset
 - Much faster and more resource efficient than BERT: appox 5 its/s on raw data with only 1 cpu core.
 - Example inference scripts is in **inference.ipynb**
 - Trained model for CNN dataset [here](https://drive.google.com/drive/folders/1CGFl9ihei9jSqoT6ITXwkU47ri9bXL1J?usp=sharing)
