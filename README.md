# Extractive Summarization with BERT-tiny
 - BERT-small + CNN Encoder + biLSTM Encoder-Decoder with R1/R2/RougeL : 30.97/12.52/27.61 on cnn (of cnn/dailymail) dataset
 - Much faster and more resource efficient than BERT
 - Example inference scripts is in **inference.ipynb**
 - Trained model for CNN dataset [here](https://drive.google.com/drive/folders/1CGFl9ihei9jSqoT6ITXwkU47ri9bXL1J?usp=sharing)
